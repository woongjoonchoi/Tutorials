{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPs42mIhhFgmXu5sswDFfj/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woongjoonchoi/Tutorials/blob/main/Pytorch/PytorchDatasetapi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HdxfXMOiAYf6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "bRHzBZFHIxog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from  itertools import count , islice\n",
        "from matplotlib.patches import Rectangle"
      ],
      "metadata": {
        "id": "DyGpbC-QJUz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MapyStyle Dataset Practice"
      ],
      "metadata": {
        "id": "9tV9ZzrqVmHi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiprocessing"
      ],
      "metadata": {
        "id": "SvbNMT_8VoOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMapDataset(torch.utils.data.Dataset) :\n",
        "    def __init__(self , start , end) :\n",
        "        super(MyMapDataset).__init__()\n",
        "        assert end>start , \"this example code only works with end> = start\"\n",
        "\n",
        "        self.start = start\n",
        "        self.end = end \n",
        "        self.data = list(range(self.start,self.end))\n",
        "    def __getitem__(self,idx) :\n",
        "        \n",
        "        worker_info  =torch.utils.data.get_worker_info()\n",
        "        worker_id = worker_info.id\n",
        "        print(f\"worekr_id : {worker_id} data : {self.data[idx]}\\n\")\n",
        "        # print()\n",
        "        # print\n",
        "        return self.data[idx]\n",
        "    def __len__(self) :\n",
        "        return len(self.data)\n",
        "\n",
        "    # def __len__(self,)"
      ],
      "metadata": {
        "id": "qNzC2P2-VpYL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_ds = MyMapDataset(3,100)"
      ],
      "metadata": {
        "id": "n7o10b9EWeep"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(map_ds,num_workers=2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iwm8dgyXWkxV",
        "outputId": "09acf6cf-1e25-4c35-a605-d4c5ea7bfccb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "worekr_id : 0 data : 3\n",
            "\n",
            "worekr_id : 1 data : 4\n",
            "worekr_id : 0 data : 5\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 6\n",
            "worekr_id : 0 data : 7\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 8\n",
            "worekr_id : 0 data : 9\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 10\n",
            "worekr_id : 0 data : 11\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 12\n",
            "worekr_id : 0 data : 13\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 14\n",
            "worekr_id : 0 data : 15\n",
            "\n",
            "worekr_id : 1 data : 16\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 18\n",
            "\n",
            "worekr_id : 1 data : 20\n",
            "worekr_id : 0 data : 17\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 19\n",
            "\n",
            "worekr_id : 0 data : 21\n",
            "\n",
            "worekr_id : 0 data : 23\n",
            "worekr_id : 1 data : 22\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 24\n",
            "worekr_id : 0 data : 25\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 26\n",
            "worekr_id : 0 data : 27\n",
            "\n",
            "worekr_id : 1 data : 28\n",
            "\n",
            "worekr_id : 0 data : 29\n",
            "\n",
            "worekr_id : 1 data : 30\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 31\n",
            "worekr_id : 1 data : 32\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 34\n",
            "worekr_id : 0 data : 33\n",
            "\n",
            "worekr_id : 1 data : 36\n",
            "\n",
            "worekr_id : 0 data : 35\n",
            "\n",
            "worekr_id : 0 data : 37\n",
            "\n",
            "worekr_id : 1 data : 38\n",
            "\n",
            "worekr_id : 0 data : 39\n",
            "\n",
            "worekr_id : 0 data : 41\n",
            "\n",
            "worekr_id : 1 data : 40\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 42\n",
            "\n",
            "worekr_id : 0 data : 43\n",
            "worekr_id : 1 data : 44\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 45\n",
            "\n",
            "worekr_id : 1 data : 46\n",
            "\n",
            "worekr_id : 0 data : 47\n",
            "worekr_id : 1 data : 48\n",
            "\n",
            "worekr_id : 0 data : 49\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 51\n",
            "\n",
            "worekr_id : 1 data : 50\n",
            "worekr_id : 0 data : 53\n",
            "\n",
            "worekr_id : 1 data : 52\n",
            "\n",
            "worekr_id : 0 data : 55\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 57\n",
            "worekr_id : 1 data : 54\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 56\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 58\n",
            "\n",
            "worekr_id : 1 data : 60\n",
            "worekr_id : 0 data : 59\n",
            "\n",
            "worekr_id : 0 data : 61\n",
            "\n",
            "worekr_id : 0 data : 63\n",
            "\n",
            "worekr_id : 0 data : 65\n",
            "worekr_id : 1 data : 62\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 67\n",
            "worekr_id : 1 data : 64\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 66\n",
            "worekr_id : 0 data : 69\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 68\n",
            "\n",
            "worekr_id : 0 data : 71\n",
            "\n",
            "worekr_id : 0 data : 73\n",
            "worekr_id : 1 data : 70\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 72\n",
            "worekr_id : 0 data : 75\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 77\n",
            "\n",
            "worekr_id : 1 data : 74\n",
            "\n",
            "worekr_id : 0 data : 79\n",
            "\n",
            "worekr_id : 1 data : 76\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 78\n",
            "worekr_id : 0 data : 81\n",
            "worekr_id : 1 data : 80\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 83\n",
            "worekr_id : 1 data : 82\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 85\n",
            "\n",
            "worekr_id : 1 data : 84\n",
            "worekr_id : 0 data : 87\n",
            "\n",
            "worekr_id : 1 data : 86\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 88\n",
            "\n",
            "worekr_id : 0 data : 89\n",
            "worekr_id : 1 data : 90\n",
            "\n",
            "\n",
            "worekr_id : 1 data : 94\n",
            "worekr_id : 1 data : 92\n",
            "\n",
            "worekr_id : 0 data : 91\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 93\n",
            "worekr_id : 1 data : 96\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 95\n",
            "worekr_id : 1 data : 98\n",
            "\n",
            "worekr_id : 0 data : 97\n",
            "\n",
            "\n",
            "worekr_id : 0 data : 99\n",
            "\n",
            "[tensor([3]), tensor([4]), tensor([5]), tensor([6]), tensor([7]), tensor([8]), tensor([9]), tensor([10]), tensor([11]), tensor([12]), tensor([13]), tensor([14]), tensor([15]), tensor([16]), tensor([17]), tensor([18]), tensor([19]), tensor([20]), tensor([21]), tensor([22]), tensor([23]), tensor([24]), tensor([25]), tensor([26]), tensor([27]), tensor([28]), tensor([29]), tensor([30]), tensor([31]), tensor([32]), tensor([33]), tensor([34]), tensor([35]), tensor([36]), tensor([37]), tensor([38]), tensor([39]), tensor([40]), tensor([41]), tensor([42]), tensor([43]), tensor([44]), tensor([45]), tensor([46]), tensor([47]), tensor([48]), tensor([49]), tensor([50]), tensor([51]), tensor([52]), tensor([53]), tensor([54]), tensor([55]), tensor([56]), tensor([57]), tensor([58]), tensor([59]), tensor([60]), tensor([61]), tensor([62]), tensor([63]), tensor([64]), tensor([65]), tensor([66]), tensor([67]), tensor([68]), tensor([69]), tensor([70]), tensor([71]), tensor([72]), tensor([73]), tensor([74]), tensor([75]), tensor([76]), tensor([77]), tensor([78]), tensor([79]), tensor([80]), tensor([81]), tensor([82]), tensor([83]), tensor([84]), tensor([85]), tensor([86]), tensor([87]), tensor([88]), tensor([89]), tensor([90]), tensor([91]), tensor([92]), tensor([93]), tensor([94]), tensor([95]), tensor([96]), tensor([97]), tensor([98]), tensor([99])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IterableDataset Practice"
      ],
      "metadata": {
        "id": "ExXH11h_WuOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IterableDataset Duplicate"
      ],
      "metadata": {
        "id": "_r7lCl_mW1Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset) :\n",
        "    def __init__(self,start, end) :\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end>start , \"this example code only works with end >=start\"\n",
        "\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "    def __iter__(self) :\n",
        "        worker_info = torch.utils.data.get_worker_info()\n",
        "        worker_id = worker_info.id\n",
        "        print(range(self.start,self.end))\n",
        "        return iter(range(self.start,self.end))\n",
        "\n"
      ],
      "metadata": {
        "id": "YAPhdY3JCshW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = MyIterableDataset(start=3 ,end =100)"
      ],
      "metadata": {
        "id": "Ck4-J-G3BvQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(ds,num_workers=2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSvQry2hB1Up",
        "outputId": "f3428f1f-16bb-4f13-d9b1-c8eb4beb3b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "range(3, 100)\n",
            "range(3, 100)\n",
            "[tensor([3]), tensor([3]), tensor([4]), tensor([4]), tensor([5]), tensor([5]), tensor([6]), tensor([6]), tensor([7]), tensor([7]), tensor([8]), tensor([8]), tensor([9]), tensor([9]), tensor([10]), tensor([10]), tensor([11]), tensor([11]), tensor([12]), tensor([12]), tensor([13]), tensor([13]), tensor([14]), tensor([14]), tensor([15]), tensor([15]), tensor([16]), tensor([16]), tensor([17]), tensor([17]), tensor([18]), tensor([18]), tensor([19]), tensor([19]), tensor([20]), tensor([20]), tensor([21]), tensor([21]), tensor([22]), tensor([22]), tensor([23]), tensor([23]), tensor([24]), tensor([24]), tensor([25]), tensor([25]), tensor([26]), tensor([26]), tensor([27]), tensor([27]), tensor([28]), tensor([28]), tensor([29]), tensor([29]), tensor([30]), tensor([30]), tensor([31]), tensor([31]), tensor([32]), tensor([32]), tensor([33]), tensor([33]), tensor([34]), tensor([34]), tensor([35]), tensor([35]), tensor([36]), tensor([36]), tensor([37]), tensor([37]), tensor([38]), tensor([38]), tensor([39]), tensor([39]), tensor([40]), tensor([40]), tensor([41]), tensor([41]), tensor([42]), tensor([42]), tensor([43]), tensor([43]), tensor([44]), tensor([44]), tensor([45]), tensor([45]), tensor([46]), tensor([46]), tensor([47]), tensor([47]), tensor([48]), tensor([48]), tensor([49]), tensor([49]), tensor([50]), tensor([50]), tensor([51]), tensor([51]), tensor([52]), tensor([52]), tensor([53]), tensor([53]), tensor([54]), tensor([54]), tensor([55]), tensor([55]), tensor([56]), tensor([56]), tensor([57]), tensor([57]), tensor([58]), tensor([58]), tensor([59]), tensor([59]), tensor([60]), tensor([60]), tensor([61]), tensor([61]), tensor([62]), tensor([62]), tensor([63]), tensor([63]), tensor([64]), tensor([64]), tensor([65]), tensor([65]), tensor([66]), tensor([66]), tensor([67]), tensor([67]), tensor([68]), tensor([68]), tensor([69]), tensor([69]), tensor([70]), tensor([70]), tensor([71]), tensor([71]), tensor([72]), tensor([72]), tensor([73]), tensor([73]), tensor([74]), tensor([74]), tensor([75]), tensor([75]), tensor([76]), tensor([76]), tensor([77]), tensor([77]), tensor([78]), tensor([78]), tensor([79]), tensor([79]), tensor([80]), tensor([80]), tensor([81]), tensor([81]), tensor([82]), tensor([82]), tensor([83]), tensor([83]), tensor([84]), tensor([84]), tensor([85]), tensor([85]), tensor([86]), tensor([86]), tensor([87]), tensor([87]), tensor([88]), tensor([88]), tensor([89]), tensor([89]), tensor([90]), tensor([90]), tensor([91]), tensor([91]), tensor([92]), tensor([92]), tensor([93]), tensor([93]), tensor([94]), tensor([94]), tensor([95]), tensor([95]), tensor([96]), tensor([96]), tensor([97]), tensor([97]), tensor([98]), tensor([98]), tensor([99]), tensor([99])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IterableDataset Remove Duplicate"
      ],
      "metadata": {
        "id": "i2vIbx3RXY9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sol1 : Using get_worker_info()"
      ],
      "metadata": {
        "id": "wWbPHCQdXcLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset) :\n",
        "    def __init__(self, start, end) :\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end > start , \"this example code only works with end >= start\"\n",
        "\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "    \n",
        "    def __iter__(self) :\n",
        "        worker_info= torch.utils.data.get_worker_info()\n",
        "        if worker_info is None :\n",
        "            iter_start = self.start\n",
        "            iter_end = self.end\n",
        "        else :\n",
        "            per_worker = int(math.ceil((self.end-self.start) ) /\n",
        "                             float(worker_info.num_workers))\n",
        "            worker_id = worker_info.id\n",
        "            iter_start = self.start + worker_id * per_worker\n",
        "            iter_end =  min(iter_start + per_worker , self.end)\n",
        "            print(f'worker_id : {worker_id} \\n iter_start : {iter_start}  iter_end : {iter_end}\\n')\n",
        "        return iter(range(iter_start, iter_end))\n"
      ],
      "metadata": {
        "id": "RP29HgOYAsgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = MyIterableDataset(start = 3 ,end = 100) "
      ],
      "metadata": {
        "id": "b_a2J6vGDEFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(ds,num_workers=3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sXV2F6dDICk",
        "outputId": "145dacf7-f139-40f3-b32c-1abe14f19ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "worker_id : 0 \n",
            " iter_start : 3  iter_end : 35\n",
            "worker_id : 1 \n",
            " iter_start : 35  iter_end : 67\n",
            "\n",
            "\n",
            "worker_id : 2 \n",
            " iter_start : 67  iter_end : 99\n",
            "\n",
            "[tensor([3]), tensor([35]), tensor([67]), tensor([4]), tensor([36]), tensor([68]), tensor([5]), tensor([37]), tensor([69]), tensor([6]), tensor([38]), tensor([70]), tensor([7]), tensor([39]), tensor([71]), tensor([8]), tensor([40]), tensor([72]), tensor([9]), tensor([41]), tensor([73]), tensor([10]), tensor([42]), tensor([74]), tensor([11]), tensor([43]), tensor([75]), tensor([12]), tensor([44]), tensor([76]), tensor([13]), tensor([45]), tensor([77]), tensor([14]), tensor([46]), tensor([78]), tensor([15]), tensor([47]), tensor([79]), tensor([16]), tensor([48]), tensor([80]), tensor([17]), tensor([49]), tensor([81]), tensor([18]), tensor([50]), tensor([82]), tensor([19]), tensor([51]), tensor([83]), tensor([20]), tensor([52]), tensor([84]), tensor([21]), tensor([53]), tensor([85]), tensor([22]), tensor([54]), tensor([86]), tensor([23]), tensor([55]), tensor([87]), tensor([24]), tensor([56]), tensor([88]), tensor([25]), tensor([57]), tensor([89]), tensor([26]), tensor([58]), tensor([90]), tensor([27]), tensor([59]), tensor([91]), tensor([28]), tensor([60]), tensor([92]), tensor([29]), tensor([61]), tensor([93]), tensor([30]), tensor([62]), tensor([94]), tensor([31]), tensor([63]), tensor([95]), tensor([32]), tensor([64]), tensor([96]), tensor([33]), tensor([65]), tensor([97]), tensor([34]), tensor([66]), tensor([98])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sol2 : Using worker_init_fn(worker_id)"
      ],
      "metadata": {
        "id": "8f-dp-cRXyTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterableDataset(torch.utils.data.IterableDataset) :\n",
        "    def __init__(self,start, end) :\n",
        "        super(MyIterableDataset).__init__()\n",
        "        assert end>start , \"this example code only works with end >=start\"\n",
        "\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "    def __iter__(self) :\n",
        "        worker_info = torch.utils.data.get_worker_info()\n",
        "        worker_id = worker_info.id\n",
        "        print(f'worker_id : {worker_id} \\n iter_start : {self.start}  iter_end : {self.end}\\n')\n",
        "        return iter(range(self.start,self.end))\n",
        "\n"
      ],
      "metadata": {
        "id": "t8Td7xpSYALc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def worker_init_fn(worker_id) :\n",
        "    worker_info = torch.utils.data.get_worker_info()\n",
        "    dataset = worker_info.dataset\n",
        "    overall_start = dataset.start\n",
        "    overall_end = dataset.end\n",
        "\n",
        "    per_worker = int(math.ceil((overall_end-overall_start) ) /\n",
        "                     float(worker_info.num_workers))\n",
        "    worker_id = worker_info.id\n",
        "    dataset.start = overall_start + worker_id * per_worker\n",
        "    dataset.end = min(dataset.start + per_worker , overall_end)\n",
        "    # print(f'worker_id : {worker_id} , worker_start : {dataset.start}  ,  worekr_end : {dataset.end}')"
      ],
      "metadata": {
        "id": "8TOzDfVCDdh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = MyIterableDataset(start = 3 ,end = 100) "
      ],
      "metadata": {
        "id": "AQDSkzNkYCD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(ds,num_workers=2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e195oSELDZ6V",
        "outputId": "8471f684-6df7-4dc1-f606-4605b9a7f5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "worker_id : 0 \n",
            " iter_start : 3  iter_end : 100\n",
            "\n",
            "worker_id : 1 \n",
            " iter_start : 3  iter_end : 100\n",
            "\n",
            "[tensor([3]), tensor([3]), tensor([4]), tensor([4]), tensor([5]), tensor([5]), tensor([6]), tensor([6]), tensor([7]), tensor([7]), tensor([8]), tensor([8]), tensor([9]), tensor([9]), tensor([10]), tensor([10]), tensor([11]), tensor([11]), tensor([12]), tensor([12]), tensor([13]), tensor([13]), tensor([14]), tensor([14]), tensor([15]), tensor([15]), tensor([16]), tensor([16]), tensor([17]), tensor([17]), tensor([18]), tensor([18]), tensor([19]), tensor([19]), tensor([20]), tensor([20]), tensor([21]), tensor([21]), tensor([22]), tensor([22]), tensor([23]), tensor([23]), tensor([24]), tensor([24]), tensor([25]), tensor([25]), tensor([26]), tensor([26]), tensor([27]), tensor([27]), tensor([28]), tensor([28]), tensor([29]), tensor([29]), tensor([30]), tensor([30]), tensor([31]), tensor([31]), tensor([32]), tensor([32]), tensor([33]), tensor([33]), tensor([34]), tensor([34]), tensor([35]), tensor([35]), tensor([36]), tensor([36]), tensor([37]), tensor([37]), tensor([38]), tensor([38]), tensor([39]), tensor([39]), tensor([40]), tensor([40]), tensor([41]), tensor([41]), tensor([42]), tensor([42]), tensor([43]), tensor([43]), tensor([44]), tensor([44]), tensor([45]), tensor([45]), tensor([46]), tensor([46]), tensor([47]), tensor([47]), tensor([48]), tensor([48]), tensor([49]), tensor([49]), tensor([50]), tensor([50]), tensor([51]), tensor([51]), tensor([52]), tensor([52]), tensor([53]), tensor([53]), tensor([54]), tensor([54]), tensor([55]), tensor([55]), tensor([56]), tensor([56]), tensor([57]), tensor([57]), tensor([58]), tensor([58]), tensor([59]), tensor([59]), tensor([60]), tensor([60]), tensor([61]), tensor([61]), tensor([62]), tensor([62]), tensor([63]), tensor([63]), tensor([64]), tensor([64]), tensor([65]), tensor([65]), tensor([66]), tensor([66]), tensor([67]), tensor([67]), tensor([68]), tensor([68]), tensor([69]), tensor([69]), tensor([70]), tensor([70]), tensor([71]), tensor([71]), tensor([72]), tensor([72]), tensor([73]), tensor([73]), tensor([74]), tensor([74]), tensor([75]), tensor([75]), tensor([76]), tensor([76]), tensor([77]), tensor([77]), tensor([78]), tensor([78]), tensor([79]), tensor([79]), tensor([80]), tensor([80]), tensor([81]), tensor([81]), tensor([82]), tensor([82]), tensor([83]), tensor([83]), tensor([84]), tensor([84]), tensor([85]), tensor([85]), tensor([86]), tensor([86]), tensor([87]), tensor([87]), tensor([88]), tensor([88]), tensor([89]), tensor([89]), tensor([90]), tensor([90]), tensor([91]), tensor([91]), tensor([92]), tensor([92]), tensor([93]), tensor([93]), tensor([94]), tensor([94]), tensor([95]), tensor([95]), tensor([96]), tensor([96]), tensor([97]), tensor([97]), tensor([98]), tensor([98]), tensor([99]), tensor([99])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(ds,num_workers=10,worker_init_fn=worker_init_fn)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQYHYNdpEeol",
        "outputId": "984fb296-880d-4176-94fc-0936e2e2341f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "worker_id : 0 \n",
            " iter_start : 3  iter_end : 12\n",
            "\n",
            "worker_id : 1 \n",
            " iter_start : 12  iter_end : 21\n",
            "worker_id : 2 \n",
            " iter_start : 21  iter_end : 30\n",
            "\n",
            "worker_id : 3 \n",
            " iter_start : 30  iter_end : 39\n",
            "\n",
            "\n",
            "worker_id : 4 \n",
            " iter_start : 39  iter_end : 48\n",
            "\n",
            "worker_id : 5 \n",
            " iter_start : 48  iter_end : 57\n",
            "\n",
            "worker_id : 6 \n",
            " iter_start : 57  iter_end : 66\n",
            "\n",
            "worker_id : 7 \n",
            " iter_start : 66  iter_end : 75\n",
            "\n",
            "worker_id : 8 \n",
            " iter_start : 75  iter_end : 84\n",
            "\n",
            "worker_id : 9 \n",
            " iter_start : 84  iter_end : 93\n",
            "\n",
            "[tensor([3]), tensor([12]), tensor([21]), tensor([30]), tensor([39]), tensor([48]), tensor([57]), tensor([66]), tensor([75]), tensor([84]), tensor([4]), tensor([13]), tensor([22]), tensor([31]), tensor([40]), tensor([49]), tensor([58]), tensor([67]), tensor([76]), tensor([85]), tensor([5]), tensor([14]), tensor([23]), tensor([32]), tensor([41]), tensor([50]), tensor([59]), tensor([68]), tensor([77]), tensor([86]), tensor([6]), tensor([15]), tensor([24]), tensor([33]), tensor([42]), tensor([51]), tensor([60]), tensor([69]), tensor([78]), tensor([87]), tensor([7]), tensor([16]), tensor([25]), tensor([34]), tensor([43]), tensor([52]), tensor([61]), tensor([70]), tensor([79]), tensor([88]), tensor([8]), tensor([17]), tensor([26]), tensor([35]), tensor([44]), tensor([53]), tensor([62]), tensor([71]), tensor([80]), tensor([89]), tensor([9]), tensor([18]), tensor([27]), tensor([36]), tensor([45]), tensor([54]), tensor([63]), tensor([72]), tensor([81]), tensor([90]), tensor([10]), tensor([19]), tensor([28]), tensor([37]), tensor([46]), tensor([55]), tensor([64]), tensor([73]), tensor([82]), tensor([91]), tensor([11]), tensor([20]), tensor([29]), tensor([38]), tensor([47]), tensor([56]), tensor([65]), tensor([74]), tensor([83]), tensor([92])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampler "
      ],
      "metadata": {
        "id": "G-6gLLdwaHFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integer indicies sampler"
      ],
      "metadata": {
        "id": "-uxvepkEadj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(100)"
      ],
      "metadata": {
        "id": "oBRUOMOxakP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MySamplerTestDataset(torch.utils.data.Dataset) :\n",
        "\n",
        "    def __init__(self , inp):\n",
        "        self.inp  =inp\n",
        "\n",
        "    def __getitem__(self , idx) :\n",
        "        return self.inp[idx]\n",
        "        ...\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.inp)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "oqK3bllz7EW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IntegerIndiciesSamplerdataset = MySamplerTestDataset(a)"
      ],
      "metadata": {
        "id": "N6Iy4Ha9ayDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(IntegerIndiciesSamplerdataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx7ilyB8jowL",
        "outputId": "aac5df35-9572-454e-b63c-8f3c1e1dd8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Randomsampler = torch.utils.data.RandomSampler(IntegerIndiciesSamplerdataset)"
      ],
      "metadata": {
        "id": "JUllyElgbLn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(IntegerIndiciesSamplerdataset , shuffle=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srhg2_yLa6Bj",
        "outputId": "e014f555-2421-4a5e-e2fb-5494c67ad6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([63]), tensor([32]), tensor([15]), tensor([25]), tensor([9]), tensor([31]), tensor([87]), tensor([68]), tensor([10]), tensor([42]), tensor([21]), tensor([72]), tensor([24]), tensor([56]), tensor([71]), tensor([70]), tensor([78]), tensor([14]), tensor([73]), tensor([83]), tensor([76]), tensor([16]), tensor([18]), tensor([5]), tensor([49]), tensor([29]), tensor([39]), tensor([77]), tensor([26]), tensor([45]), tensor([52]), tensor([8]), tensor([86]), tensor([17]), tensor([7]), tensor([88]), tensor([59]), tensor([55]), tensor([54]), tensor([35]), tensor([22]), tensor([0]), tensor([57]), tensor([92]), tensor([20]), tensor([64]), tensor([75]), tensor([43]), tensor([85]), tensor([1]), tensor([2]), tensor([89]), tensor([46]), tensor([28]), tensor([11]), tensor([82]), tensor([80]), tensor([91]), tensor([27]), tensor([6]), tensor([79]), tensor([44]), tensor([19]), tensor([58]), tensor([4]), tensor([47]), tensor([90]), tensor([51]), tensor([81]), tensor([33]), tensor([67]), tensor([50]), tensor([61]), tensor([3]), tensor([97]), tensor([93]), tensor([84]), tensor([48]), tensor([34]), tensor([66]), tensor([62]), tensor([41]), tensor([53]), tensor([23]), tensor([74]), tensor([60]), tensor([96]), tensor([30]), tensor([69]), tensor([12]), tensor([37]), tensor([65]), tensor([98]), tensor([13]), tensor([36]), tensor([38]), tensor([94]), tensor([95]), tensor([99]), tensor([40])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(IntegerIndiciesSamplerdataset,sampler=None )))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E33CMGr7jd59",
        "outputId": "a1e1d6a1-77cd-4220-e82b-5b926a63bf78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([0]), tensor([1]), tensor([2]), tensor([3]), tensor([4]), tensor([5]), tensor([6]), tensor([7]), tensor([8]), tensor([9]), tensor([10]), tensor([11]), tensor([12]), tensor([13]), tensor([14]), tensor([15]), tensor([16]), tensor([17]), tensor([18]), tensor([19]), tensor([20]), tensor([21]), tensor([22]), tensor([23]), tensor([24]), tensor([25]), tensor([26]), tensor([27]), tensor([28]), tensor([29]), tensor([30]), tensor([31]), tensor([32]), tensor([33]), tensor([34]), tensor([35]), tensor([36]), tensor([37]), tensor([38]), tensor([39]), tensor([40]), tensor([41]), tensor([42]), tensor([43]), tensor([44]), tensor([45]), tensor([46]), tensor([47]), tensor([48]), tensor([49]), tensor([50]), tensor([51]), tensor([52]), tensor([53]), tensor([54]), tensor([55]), tensor([56]), tensor([57]), tensor([58]), tensor([59]), tensor([60]), tensor([61]), tensor([62]), tensor([63]), tensor([64]), tensor([65]), tensor([66]), tensor([67]), tensor([68]), tensor([69]), tensor([70]), tensor([71]), tensor([72]), tensor([73]), tensor([74]), tensor([75]), tensor([76]), tensor([77]), tensor([78]), tensor([79]), tensor([80]), tensor([81]), tensor([82]), tensor([83]), tensor([84]), tensor([85]), tensor([86]), tensor([87]), tensor([88]), tensor([89]), tensor([90]), tensor([91]), tensor([92]), tensor([93]), tensor([94]), tensor([95]), tensor([96]), tensor([97]), tensor([98]), tensor([99])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for kk in torch.utils.data.DataLoader(IntegerIndiciesSamplerdataset,sampler=None , batch_sampler=None ) :\n",
        "    print(kk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "U79Q42Arlb9Y",
        "outputId": "ded651a6-f7bd-43a8-f31b-8bc2c5d5914c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5e1ffb722fca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIntegerIndiciesSamplerdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'MySamplerTestDataset' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NonIntegral indicies sampler"
      ],
      "metadata": {
        "id": "cgH9l1Y6akvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(100)"
      ],
      "metadata": {
        "id": "nyzwaDQT7dcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = np.arange(100 , 200)"
      ],
      "metadata": {
        "id": "3e5eUwR5-XAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.arange(200,300)"
      ],
      "metadata": {
        "id": "9fQIeuUc-cPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {'a' : a, 'b' :b , 'c' : c}"
      ],
      "metadata": {
        "id": "g7lPbxVw-e5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MySamplerTestDataset(torch.utils.data.Dataset) :\n",
        "\n",
        "    def __init__(self , inp):\n",
        "        self.inp  =inp\n",
        "\n",
        "    def __getitem__(self , idx) :\n",
        "        print(f\"idx : {idx}\")\n",
        "        return self.inp[idx]\n",
        "        ...\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.inp)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "-kkIVd0S-mSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSampler(torch.utils.data.Sampler) :\n",
        "    def __init__(self, data_source) :\n",
        "        self.data_source = data_source\n",
        "    def __iter__(self) :\n",
        "        print('hi')\n",
        "\n",
        "        return iter(self.data_source)\n",
        "        # return iter(['a' , 'b' , 'c'])\n",
        "    def __len__(self) :\n",
        "        return len(self.data_source)"
      ],
      "metadata": {
        "id": "32cYyk9q-sx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NonintegerSamplerTestDataset = MySamplerTestDataset(dic)"
      ],
      "metadata": {
        "id": "Jq_gryMPbjJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonintegersampler = CustomSampler(dic)"
      ],
      "metadata": {
        "id": "OrDrVojObq4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(NonintegerSamplerTestDataset , sampler = nonintegersampler)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNOcbIl4b34O",
        "outputId": "a756fb3f-5962-4134-f904-04d4bffecf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n",
            "idx : a\n",
            "idx : b\n",
            "idx : c\n",
            "[tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
            "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
            "         90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]), tensor([[100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
            "         114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
            "         128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
            "         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
            "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
            "         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
            "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
            "         198, 199]]), tensor([[200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
            "         214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
            "         228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
            "         242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255,\n",
            "         256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
            "         270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
            "         284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
            "         298, 299]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterable can not use sampler or batch sampler"
      ],
      "metadata": {
        "id": "YA0SNnyCcUqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(100)"
      ],
      "metadata": {
        "id": "Wz6umviAL1fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = np.arange(100 , 200)"
      ],
      "metadata": {
        "id": "NuKgH-2aL1fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.arange(200,300)"
      ],
      "metadata": {
        "id": "rpnWB7SLL1fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {'a' : a, 'b' :b , 'c' : c}"
      ],
      "metadata": {
        "id": "exRRBF0JL1fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MySamplerTestIterableDatset(torch.utils.data.IterableDataset) :\n",
        "    def __init__(self,inp) :\n",
        "        self.inp =inp \n",
        "    def __iter__(self) :\n",
        "        return iter(self.inp)\n",
        "    def __len__(self) :\n",
        "        return len(self.inp)"
      ],
      "metadata": {
        "id": "C3gumMA1CvWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itercustomsamplerdataset = MySamplerTestIterableDatset(dic)"
      ],
      "metadata": {
        "id": "or86LCb6DNVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch predefined sampler test"
      ],
      "metadata": {
        "id": "Vxh34JNWch6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "itersampler  = torch.utils.data.RandomSampler(itercustomsamplerdataset)"
      ],
      "metadata": {
        "id": "VttEmSexDuug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterable dataset  sampler, batch_sampler ,batch_size  .\n",
        "\n",
        "print(list(torch.utils.data.DataLoader(itercustomsamplerdataset ,batch_size = 4, batch_sampler = itersampler)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FrSqpd3JDkOp",
        "outputId": "c782de04-5b3f-42fb-b30b-0a851c5851c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-5a86c478aaf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# iterable dataset  sampler, batch_sampler ,batch_size  .\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitercustomsamplerdataset\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitersampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 raise ValueError(\n\u001b[1;32m    239\u001b[0m                     \u001b[0;34m\"DataLoader with IterableDataset: expected unspecified \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                     \"batch_sampler option, but got batch_sampler={}\".format(batch_sampler))\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataLoader with IterableDataset: expected unspecified batch_sampler option, but got batch_sampler=<torch.utils.data.sampler.RandomSampler object at 0x7f5511cf1690>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(itercustomsamplerdataset ,batch_size = 4, sampler = itersampler)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "I4AtrI1LculQ",
        "outputId": "73a90d8a-afd6-4b08-bf52-705e826b985c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-7c435a8ff191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitercustomsamplerdataset\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitersampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 raise ValueError(\n\u001b[1;32m    234\u001b[0m                     \u001b[0;34m\"DataLoader with IterableDataset: expected unspecified \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                     \"sampler option, but got sampler={}\".format(sampler))\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mbatch_sampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;31m# See NOTE [ Custom Samplers and IterableDataset ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataLoader with IterableDataset: expected unspecified sampler option, but got sampler=<torch.utils.data.sampler.RandomSampler object at 0x7f5511cf1690>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch custom sampler test"
      ],
      "metadata": {
        "id": "V9_qsLGaczRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSampler(torch.utils.data.Sampler) :\n",
        "    def __init__(self, data_source) :\n",
        "        self.data_source = data_source\n",
        "    def __iter__(self) :\n",
        "        print('hi')\n",
        "\n",
        "        return iter(self.data_source)\n",
        "        # return iter(['a' , 'b' , 'c'])\n",
        "    def __len__(self) :\n",
        "        return len(self.data_source)"
      ],
      "metadata": {
        "id": "FbZ9orwRLyUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonintegersampler = CustomSampler(dic)"
      ],
      "metadata": {
        "id": "SKV4rIs8Lysg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(itercustomsamplerdataset , sampler = nonintegersampler)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "ViTOuDu5c4sR",
        "outputId": "822be38c-ac53-4986-9e9c-3887cf686165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-685f9c958dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitercustomsamplerdataset\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonintegersampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 raise ValueError(\n\u001b[1;32m    234\u001b[0m                     \u001b[0;34m\"DataLoader with IterableDataset: expected unspecified \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                     \"sampler option, but got sampler={}\".format(sampler))\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mbatch_sampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;31m# See NOTE [ Custom Samplers and IterableDataset ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataLoader with IterableDataset: expected unspecified sampler option, but got sampler=<__main__.CustomSampler object at 0x7f5511ce5c50>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(itercustomsamplerdataset , batch_sampler = nonintegersampler)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "bPch70WIdBwe",
        "outputId": "65759da5-c0d1-4b44-dd39-563bab880079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-81f940104d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitercustomsamplerdataset\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonintegersampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 raise ValueError(\n\u001b[1;32m    239\u001b[0m                     \u001b[0;34m\"DataLoader with IterableDataset: expected unspecified \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                     \"batch_sampler option, but got batch_sampler={}\".format(batch_sampler))\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataLoader with IterableDataset: expected unspecified batch_sampler option, but got batch_sampler=<__main__.CustomSampler object at 0x7f5511ce5c50>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4qtR3mDrWREd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Batch Sampler"
      ],
      "metadata": {
        "id": "OiNYmSE_WfLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MySamplerTestDataset(torch.utils.data.Dataset) :\n",
        "\n",
        "    def __init__(self , inp):\n",
        "        self.inp  =inp\n",
        "\n",
        "    def __getitem__(self , idx) :\n",
        "        return self.inp[idx]\n",
        "        ...\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.inp)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "EkQHqR1VWjJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSampler(torch.utils.data.Sampler) :\n",
        "    def __init__(self, data_source) :\n",
        "        self.data_source = data_source\n",
        "    def __iter__(self) :\n",
        "        print('hi')\n",
        "\n",
        "        return iter(np.split(self.data_source,10))\n",
        "        # return iter(['a' , 'b' , 'c'])\n",
        "    def __len__(self) :\n",
        "        return len(self.data_source)"
      ],
      "metadata": {
        "id": "VIwKdFMoWvXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(100)"
      ],
      "metadata": {
        "id": "DZj7tDQOXtdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dds  = MySamplerTestDataset(a)"
      ],
      "metadata": {
        "id": "xCJ_qedA75XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customsampler = CustomSampler(a)"
      ],
      "metadata": {
        "id": "c0AfMMOhW06d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### using sampler argument"
      ],
      "metadata": {
        "id": "XC8aXbyPY52u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 element  sequence 2 batch   tensor  return.\n",
        "\n",
        "#for index in sampler:\n",
        "    # yield collate_fn(dataset[index])\n",
        "\n",
        "ddd = list(torch.utils.data.DataLoader(dds,sampler = customsampler , batch_size = 2 ))\n",
        "for dd in ddd :\n",
        "    print(dd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW59VrQ08Tdm",
        "outputId": "b75495a9-1e39-490b-b58e-95fdbeaa988a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
            "tensor([[20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
            "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]])\n",
            "tensor([[40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
            "        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]])\n",
            "tensor([[60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
            "        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79]])\n",
            "tensor([[80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
            "        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### using batch_sampler argument"
      ],
      "metadata": {
        "id": "-y62wy1WY8uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddd = list(torch.utils.data.DataLoader(dds,batch_sampler = customsampler  ))\n",
        "\n",
        "#for indices in batch_sampler:\n",
        "    # yield collate_fn([dataset[i] for i in indices])\n",
        "for dd in ddd :\n",
        "    print(dd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "983E5rooYwfX",
        "outputId": "a02a0154-4315-40a1-98de-19f104106b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
            "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
            "tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
            "tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
            "tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
            "tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
            "tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
            "tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
            "tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddd = list(torch.utils.data.DataLoader(dds,batch_sampler = customsampler ,batch_size= 3 ))\n",
        "\n",
        "#for indices in batch_sampler:\n",
        "    # yield collate_fn([dataset[i] for i in indices])\n",
        "for dd in ddd :\n",
        "    print(dd)"
      ],
      "metadata": {
        "id": "FnidMLkNXxH_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "2716ff98-eac7-4b37-e555-8015abae394d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-05e1dcc877a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustomsampler\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#for indices in batch_sampler:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# yield collate_fn([dataset[i] for i in indices])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mddd\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;31m# auto_collation with custom batch_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 raise ValueError('batch_sampler option is mutually exclusive '\n\u001b[0m\u001b[1;32m    252\u001b[0m                                  \u001b[0;34m'with batch_size, shuffle, sampler, and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                  'drop_last')\n",
            "\u001b[0;31mValueError\u001b[0m: batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch"
      ],
      "metadata": {
        "id": "XxgYvAAkdRgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic Batching"
      ],
      "metadata": {
        "id": "Kcw7imdgeKxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Map-style dataset"
      ],
      "metadata": {
        "id": "bSxfqy1WePld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MySamplerTestDataset(torch.utils.data.Dataset) :\n",
        "\n",
        "    def __init__(self , inp):\n",
        "        self.inp  =inp\n",
        "\n",
        "    def __getitem__(self , idx) :\n",
        "        return self.inp[idx]\n",
        "        ...\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.inp)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "OIxhWFvvdcrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(100)"
      ],
      "metadata": {
        "id": "BYk-o8DtdwBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BatchtestDataset = MySamplerTestDataset(a)"
      ],
      "metadata": {
        "id": "o2pFK0Jedwlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(BatchtestDataset, batch_size = 6)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK_AfOTSd1cJ",
        "outputId": "583d76cf-c199-4790-af81-3b67211cbffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([0, 1, 2, 3, 4, 5]), tensor([ 6,  7,  8,  9, 10, 11]), tensor([12, 13, 14, 15, 16, 17]), tensor([18, 19, 20, 21, 22, 23]), tensor([24, 25, 26, 27, 28, 29]), tensor([30, 31, 32, 33, 34, 35]), tensor([36, 37, 38, 39, 40, 41]), tensor([42, 43, 44, 45, 46, 47]), tensor([48, 49, 50, 51, 52, 53]), tensor([54, 55, 56, 57, 58, 59]), tensor([60, 61, 62, 63, 64, 65]), tensor([66, 67, 68, 69, 70, 71]), tensor([72, 73, 74, 75, 76, 77]), tensor([78, 79, 80, 81, 82, 83]), tensor([84, 85, 86, 87, 88, 89]), tensor([90, 91, 92, 93, 94, 95]), tensor([96, 97, 98, 99])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(BatchtestDataset, batch_size = 6 ,drop_last = True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaMPrUmpeGaA",
        "outputId": "5b9e39fb-6038-412d-e8fd-eb35c2e9f6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([0, 1, 2, 3, 4, 5]), tensor([ 6,  7,  8,  9, 10, 11]), tensor([12, 13, 14, 15, 16, 17]), tensor([18, 19, 20, 21, 22, 23]), tensor([24, 25, 26, 27, 28, 29]), tensor([30, 31, 32, 33, 34, 35]), tensor([36, 37, 38, 39, 40, 41]), tensor([42, 43, 44, 45, 46, 47]), tensor([48, 49, 50, 51, 52, 53]), tensor([54, 55, 56, 57, 58, 59]), tensor([60, 61, 62, 63, 64, 65]), tensor([66, 67, 68, 69, 70, 71]), tensor([72, 73, 74, 75, 76, 77]), tensor([78, 79, 80, 81, 82, 83]), tensor([84, 85, 86, 87, 88, 89]), tensor([90, 91, 92, 93, 94, 95])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterable Style dataset"
      ],
      "metadata": {
        "id": "e2sDaHUXejgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MySamplerTestIterableDatset(torch.utils.data.IterableDataset) :\n",
        "    def __init__(self,inp) :\n",
        "        self.inp =inp \n",
        "    def __iter__(self) :\n",
        "        return iter(self.inp)\n",
        "    def __len__(self) :\n",
        "        return len(self.inp)"
      ],
      "metadata": {
        "id": "py4XSyWAemjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(100)"
      ],
      "metadata": {
        "id": "HGsDYPchfBgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BatchiterabletestDataset = MySamplerTestIterableDatset(a)"
      ],
      "metadata": {
        "id": "fDuHMQlPfCpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(torch.utils.data.DataLoader(BatchiterabletestDataset, batch_size = 10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mrIE2mcXjDh",
        "outputId": "b07f4849-d96b-4edf-ac6f-c526ab722ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]), tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]), tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]), tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]), tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]), tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_s = np.random.shuffle(a)"
      ],
      "metadata": {
        "id": "MX8YCgzSKTc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(np.split(a,10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH-ME9v0KYkv",
        "outputId": "c7192373-8549-4458-c90c-3a71829f051b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([86, 53, 58, 44, 25, 19, 45, 40,  8, 39]), array([90, 95, 94,  9,  5, 22, 70, 43, 14, 83]), array([92, 55, 96, 30,  7, 89, 42, 93, 74,  6]), array([17, 65, 57, 79, 69, 24, 29, 61, 11, 71]), array([13, 98, 34, 85, 16,  2,  3, 72, 50, 26]), array([76, 68, 27, 82, 66, 48, 12, 78, 77, 28]), array([23, 62, 73, 36, 99, 49, 84, 59,  0, 56]), array([75, 88, 60, 35, 81, 33,  1, 54, 87, 51]), array([38, 47, 67,  4, 20, 21, 31, 91, 18, 64]), array([63, 46, 41, 97, 10, 37, 80, 15, 52, 32])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non Automatic Batching"
      ],
      "metadata": {
        "id": "uygOsryIXxiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Sampler"
      ],
      "metadata": {
        "id": "JkMJTb1lYbK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dds  = MySamplerTestDataset(a)"
      ],
      "metadata": {
        "id": "GGKriWo6X_1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customsampler= CustomSampler(dic)"
      ],
      "metadata": {
        "id": "gVsIRyW3_Tq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch\n",
        "#for index in sampler:\n",
        "    # yield collate_fn(dataset[index])\n",
        "# index sequence type   .\n",
        "# collate_fn automatic_batch disabled  default numpy array tensor  \n",
        "# numpy array  operation   . \n",
        "\n",
        "print(list(torch.utils.data.DataLoader(dds,sampler = customsampler)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl-2XH87YGPH",
        "outputId": "fd26dec1-85d8-4bb9-a474-f62eeb56d40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n",
            "[tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]), tensor([[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]), tensor([[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]]), tensor([[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]]), tensor([[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]]), tensor([[50, 51, 52, 53, 54, 55, 56, 57, 58, 59]]), tensor([[60, 61, 62, 63, 64, 65, 66, 67, 68, 69]]), tensor([[70, 71, 72, 73, 74, 75, 76, 77, 78, 79]]), tensor([[80, 81, 82, 83, 84, 85, 86, 87, 88, 89]]), tensor([[90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### custom collate_fn"
      ],
      "metadata": {
        "id": "2wftyVMMYeVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MySamplerTestDataset(torch.utils.data.Dataset) :\n",
        "\n",
        "    def __init__(self , inp ,max_len):\n",
        "        self.inp  =inp\n",
        "        self.max_len = max_len\n",
        "    def __getitem__(self , idx) :\n",
        "        return self.inp[idx]\n",
        "        ...\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.inp)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "sLgw73J0ftVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSampler(torch.utils.data.Sampler) :\n",
        "    def __init__(self, data_source) :\n",
        "        self.data_source = data_source\n",
        "    def __iter__(self) :\n",
        "        print('hi')\n",
        "\n",
        "        return iter(self.data_source)\n",
        "        # return iter(['a' , 'b' , 'c'])\n",
        "    def __len__(self) :\n",
        "        return len(self.data_source)"
      ],
      "metadata": {
        "id": "UzzGvtrNfhyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate(dataset) :\n",
        "\n",
        "    # batch size    batch size =  1 ,  pytorch  dataset iterable argument .\n",
        "    # print(type(dataset))\n",
        "    dataset[0] = np.pad(dataset[0],pad_width = (0,max_len-len(dataset[0])) , mode='constant' ,constant_values=-1)\n",
        "    \n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "zI9VladuV3PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_autobatch_custom_collate(dataset) :\n",
        "\n",
        "    # batch size    batch size =  1 ,  pytorch  dataset iterable argument .\n",
        "    # print(type(dataset))\n",
        "    dataset = np.pad(dataset,pad_width = (0,max_len-len(dataset)) , mode='constant' ,constant_values=-1)\n",
        "    \n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "rG5MFyLX9Ozn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indicies = [ ]\n",
        "d = 0\n",
        "for x in range(14) :\n",
        "    d+=x\n",
        "    indicies.append(d)"
      ],
      "metadata": {
        "id": "g1aap0fxaEzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.arange(100)"
      ],
      "metadata": {
        "id": "bj1Y7I0tZzFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_a=  np.split(a,indicies)"
      ],
      "metadata": {
        "id": "lWlMtcOAa-fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(new_a[3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtEwSTedmrSO",
        "outputId": "5658547d-3ecd-4771-c54a-61764fc030ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=0\n",
        "for k in new_a :\n",
        "    max_len = max(len(k),max_len)"
      ],
      "metadata": {
        "id": "BahWZyBOhuNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   code      \n",
        "# jupyter lab  module scope max_len  reference \n",
        "\n",
        "custom_collate.max_len = max_len"
      ],
      "metadata": {
        "id": "-gyvJbZ0kPDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dds = MySamplerTestDataset(new_a,max_len)"
      ],
      "metadata": {
        "id": "mQePYQp9e9ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Automatic batching with custom collate fn\")\n",
        "\n",
        "for _dd in torch.utils.data.DataLoader(dds ,collate_fn= custom_collate) : \n",
        "    print(len(_dd[0])) \n",
        "    print(_dd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t9BMrzqfOPp",
        "outputId": "4f0576a4-1a81-4a3e-b9c4-4f2e446461a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic batching with custom collate fn\n",
            "13\n",
            "[array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([ 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([ 1,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([ 3,  4,  5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([ 6,  7,  8,  9, -1, -1, -1, -1, -1, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([10, 11, 12, 13, 14, -1, -1, -1, -1, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([15, 16, 17, 18, 19, 20, -1, -1, -1, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([21, 22, 23, 24, 25, 26, 27, -1, -1, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([28, 29, 30, 31, 32, 33, 34, 35, -1, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([36, 37, 38, 39, 40, 41, 42, 43, 44, -1, -1, -1, -1])]\n",
            "13\n",
            "[array([45, 46, 47, 48, 49, 50, 51, 52, 53, 54, -1, -1, -1])]\n",
            "13\n",
            "[array([55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, -1, -1])]\n",
            "13\n",
            "[array([66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, -1])]\n",
            "13\n",
            "[array([78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])]\n",
            "13\n",
            "[array([91, 92, 93, 94, 95, 96, 97, 98, 99, -1, -1, -1, -1])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Non Automatic Batching using custom collate_fn\")\n",
        "\n",
        "for _dd in torch.utils.data.DataLoader(dds ,batch_size = None  ,collate_fn= non_autobatch_custom_collate) : \n",
        "    print(len(_dd)) \n",
        "    print(_dd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhPj7zfz9dbB",
        "outputId": "15945aeb-5f1f-4194-d035-4cab6c02ffa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non Automatic Batching using custom collate_fn\n",
            "13\n",
            "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            "13\n",
            "[ 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            "13\n",
            "[ 1  2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            "13\n",
            "[ 3  4  5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            "13\n",
            "[ 6  7  8  9 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            "13\n",
            "[10 11 12 13 14 -1 -1 -1 -1 -1 -1 -1 -1]\n",
            "13\n",
            "[15 16 17 18 19 20 -1 -1 -1 -1 -1 -1 -1]\n",
            "13\n",
            "[21 22 23 24 25 26 27 -1 -1 -1 -1 -1 -1]\n",
            "13\n",
            "[28 29 30 31 32 33 34 35 -1 -1 -1 -1 -1]\n",
            "13\n",
            "[36 37 38 39 40 41 42 43 44 -1 -1 -1 -1]\n",
            "13\n",
            "[45 46 47 48 49 50 51 52 53 54 -1 -1 -1]\n",
            "13\n",
            "[55 56 57 58 59 60 61 62 63 64 65 -1 -1]\n",
            "13\n",
            "[66 67 68 69 70 71 72 73 74 75 76 77 -1]\n",
            "13\n",
            "[78 79 80 81 82 83 84 85 86 87 88 89 90]\n",
            "13\n",
            "[91 92 93 94 95 96 97 98 99 -1 -1 -1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ebTql-_R9Zse"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}